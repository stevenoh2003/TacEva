<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>TacEva: A Performance Evaluation Framework for Vision-Based Tactile Sensors</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">TacEva: A Performance Evaluation Framework for Vision-Based Tactile Sensors</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Author</a><sup>*</sup>,</span>
                <!-- <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Second Author</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a>
                  </span> -->
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Institution Name<br>Conferance name and year</span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img style="width: 80%; display: block; margin: 0 auto; padding-bottom: 30px;" src="static/images/system_pipeline.png" alt="Research framework diagram">
      <h2 class="subtitle has-text-centered">
        We propose a comprehensive framework for evaluating vision-based tactile sensors, systematically comparing performance across spatial resolution, sensitivity, and robustness metrics. In this paper, we test and showcase our framework against four representative VBTS (ViTacTip, MagicTac, GelSight, GelSightWM).
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Vision-based tactile sensors (VBTS) have gained
            widespread application in robotic tasks, which is attributed to
            their high spatial resolution and relatively low manufacturing
            costs. In current research, variations in sensing mechanisms,
            structural dimensions, and other parameters among different
            VBTS lead to significant performance disparities. This diversity
            creates challenges for users to optimize VBTS for specific tasks, as
            the initial choice and subsequent fine-tuning can be hindered by
            a lack of standardized metrics. To address this issue, this study
            proposes Tac-Evaluate, a comprehensive evaluation framework
            for the quantitative analysis of VBTS performance. We first
            define a set of performance metrics tailored to typical application
            scenarios, specifically chosen to represent key quantitative char-
            acteristics of VBTS. For each metric, we design an experimental
            pipeline that provides a structured framework for performance
            quantification. This evaluation approach is then applied to
            multiple VBTSs based on different sensing principles to conduct
            performance assessments. The experimental results demonstrate
            that this framework provides a thorough evaluation of VBTS
            multifunctionality and offers precise quantitative indicators for
            each performance dimension. This supports researchers in pre-
            selecting appropriate VBTS for specific tasks and provides
            performance-guided insights for optimizing the design of VBTS.
                    </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="hero is-small">
  <div class="section-container">
    <h2 style="padding-top: 10px;" class="title is-3">Calibration</h2>
  
    <div class="hero-body">
      <img style="width: 80%; display: block; margin: 0 auto;" src="static/images/calibration.png" alt="VBTS calibration setup diagram">
      
      <p><strong>Two-Stage Calibration:</strong> Our framework implements sequential calibration procedures: (1) <em>Surface-geometry reconstruction</em> to map the 3D sensor surface using a robotic arm and force-sensitive spherical indenter (10mm radius), and (2) <em>Force-localization calibration</em> establishing optical-output-to-force mappings through systematic probing.</p>

      <img style="width: 70%; display: block; margin: 2rem auto;" src="static/images/calibration_error_3.png" alt="Calibration error results">

      <p><strong>Methodology:</strong> Using a 6-axis F/T sensor and UFactory 850 robotic arm, we:</p>
      <ul style="margin-left: 1.5em; padding-left: 1.5em;">
        <li>Reconstruct surface geometry via 0.1mm-step contact probing (0.02N threshold)</li>
        <li>Generate randomized normal/shear force stimuli (x-y displacements + depth variations)</li>
        <li>Train ResNet-18 models on synchronized camera-force data (70:20:10 train-val-test split)</li>
      </ul>

      <p><strong>Key Advantage:</strong> This approach creates precise reference geometries and force-response models while accounting for both normal and shear force interactions across the entire sensing surface.</p>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="section-container">
        <h2 style="padding-top: 10px;" class="title is-3">Spatial Resolution</h2>
  
    <div class="hero-body">
      <img style="width: 80%; display: block; margin: 0 auto;" src="static/images/spatial_res_7.png" alt="Description">
        
      <p>We evaluated each sensor's ability to distinguish closely spaced contact points by testing their performance across features ranging from 0.25mm to 1.75mm. Using 3D-printed samples and 100 repeated presses per sample (with randomized orientations), we measured classification accuracy at different tolerance thresholds to determine spatial resolution.</p>
      
      <p><strong>Key Findings:</strong> All sensors achieved near-perfect accuracy at resolutions above 5mm. At the challenging 0.05mm threshold:</p>
        
      <ul style="margin-left: 1.5em; padding-left: 1.5em;">
        <li><strong>Gelmini series</strong> maintained exceptional performance (99% accuracy)</li>
        <li><strong>MagicTac</strong> showed similar high-resolution capabilities</li>
        <li><strong>ViTacTip</strong> accuracy dropped to 80%, indicating limitations in fine discrimination</li>
      </ul>
      
      <p>These results demonstrate the Gelmini and MagicTac sensors' superior ability to resolve fine spatial details, making them better suited for applications requiring high-resolution tactile feedback.</p>
    
    </div>
    <div class="sketchfab-container" style="width: 100%; max-width: 900px; margin: 0 auto; text-align: center;">
      <div class="sketchfab-embed-wrapper" style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
        <iframe 
          title="overall v1" 
          style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" 
          frameborder="0" 
          allowfullscreen 
          mozallowfullscreen="true" 
          webkitallowfullscreen="true" 
          allow="autoplay; fullscreen; xr-spatial-tracking" 
          xr-spatial-tracking 
          execution-while-out-of-viewport 
          execution-while-not-rendered 
          web-share 
          src="https://sketchfab.com/models/c2f5364ba28c44ed94dbd2674da013a5/embed">
        </iframe>
      </div>
      <p style="font-size: 13px; font-weight: normal; margin: 5px; color: #4A4A4A;">
        <a href="https://sketchfab.com/3d-models/overall-v1-c2f5364ba28c44ed94dbd2674da013a5?utm_medium=embed&utm_campaign=share-popup&utm_content=c2f5364ba28c44ed94dbd2674da013a5" target="_blank" rel="nofollow" style="font-weight: bold; color: #1CAAD9;">overall v1</a> by <a href="https://sketchfab.com/stevenoh2003?utm_medium=embed&utm_campaign=share-popup&utm_content=c2f5364ba28c44ed94dbd2674da013a5" target="_blank" rel="nofollow" style="font-weight: bold; color: #1CAAD9;">stevenoh2003</a> on <a href="https://sketchfab.com?utm_medium=embed&utm_campaign=share-popup&utm_content=c2f5364ba28c44ed94dbd2674da013a5" target="_blank" rel="nofollow" style="font-weight: bold; color: #1CAAD9;">Sketchfab</a>
      </p>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="section-container">
        <h2 style="padding-top: 10px;" class="title is-3">Sensitivity</h2>
  

    <div class="hero-body">
      <img style="width: 80%; display: block; margin: 0 auto;" src="static/images/sensitivity.png" alt="Description">
      <p>
        <strong>Sensitivity Analysis:</strong> We define tactile sensor sensitivity as <em>S</em> = Δ<em>z</em>/<em>F</em>, where Δ<em>z</em> is indentation depth and <em>F</em> is applied normal force, measuring how effectively small input changes convert to output signals. To evaluate this, robots performed systematic 0.1 mm increment indentations across sensor surfaces, recording force-displacement data at each grid point (Fig. 4). This generated spatial sensitivity maps revealing local responsiveness variations.
      </p>
      
      <p>
        <strong>Key Findings:</strong> ViTacTip showed distinct sensitivity patterns, with central regions (~4 mm/N) being half as sensitive as edges, indicating greater edge deformation under equal force. Comparative analysis across four VBTS demonstrated how sensitivity distributions vary by sensor design, with ViTacTip's edge-enhanced sensitivity contrasting with more uniform distributions in other tested sensors.
      </p>


    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="section-container">
        <h2 style="padding-top: 10px;" class="title is-3">Spatial Robustness</h2>
  

    <div class="hero-body">
      <img style="width: 90%; display: block; margin: 0 auto; padding-bottom: 30px;" src="static/images/spatial_robustness.png" alt="Description">
      <p>
        <strong>Spatial Robustness Analysis:</strong> We evaluated how consistently sensors perform when contact location varies across their surface, a critical property for real-world applications. Testing four sensors (ViTacTip, MagicTac, Gelmini, GelminiWM), we measured MAE and variability for position (P<sub>xy</sub>, P<sub>z</sub>) and force (F<sub>xy</sub>, F<sub>z</sub>) estimation across radial positions and indentation depths (Fig. 5). ViTacTip showed superior position accuracy (0.5 mm MAE, 0.216 mm STD) due to its spherical cavity design, while Gel-based sensors exhibited higher edge errors from planar optical distortions.
      </p>
      
      <p>
        <strong>Key Performance Patterns:</strong> Force estimation revealed distinct sensor behaviors - ViTacTip maintained low errors (0.02 N F<sub>z</sub> MAE) across all locations, while other sensors showed significant edge degradation. Depth analysis showed all sensors improve position accuracy with deeper indentations, but force estimation became more challenging at greater depths for Gel-based designs. The results demonstrate how sensor geometry (spherical vs. planar) and marker visibility fundamentally affect spatial robustness, with ViTacTip's design providing more uniform performance across contact locations.
      </p>


    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="section-container">
        <h2 style="padding-top: 10px;" class="title is-3">Lightning Robustness</h2>
  

    <div class="hero-body">
      <img style="width: 90%; display: block; margin: 0 auto;" src="static/images/lightning_robustness.png" alt="Description">
      <div class="lighting-analysis">
        <div class="text-with-image">
          <img src="static/images/lightning_robustness_table.png" class="wrapped-image right" alt="Lighting robustness comparison table">
          
          <p>
            <strong>Lighting Robustness Analysis:</strong> We evaluated sensor performance under varying illumination conditions (diffuse, point-source, and mixed lighting at different intensities) using two metrics: sensitivity score (S<sub>c</sub>) and robustness score (R<sub>c</sub>). ViTacTip showed significant sensitivity to lighting changes (MAE increasing 10x under 7x brighter point sources), while MagicTac demonstrated better resistance to diffuse lighting due to its internal grid structure's refraction effects - though its photometric stereo-based system became unreliable when external light interfered with its RGB illumination.
          </p>
          
          <p>
            <strong>Comparative Performance:</strong> The results reveal complementary strengths - ViTacTip maintains better tangent-force and position robustness, while MagicTac excels in normal-force estimation. For normal position estimation, both sensors performed similarly, with ViTacTip showing slightly better average accuracy. MagicTac's embedded markers in lattice structure caused tracking challenges under variable lighting, while ViTacTip's material properties made it more vulnerable to intensity variations (Fig. 6c).
          </p>
        </div>
      </div>
      
      <style>
        .text-with-image {
          display: flow-root; /* Contains floats */
        }
        
        .wrapped-image {
          margin-bottom: 1rem;
          max-width: 50%; /* Adjust as needed */
          height: auto;
        }
        
        .wrapped-image.right {
          float: right;
          margin-left: 1rem;
          margin-right: 0;
        }
        
        @media (max-width: 768px) {
          .wrapped-image {
            float: none;
            max-width: 100%;
            margin: 0 auto 1rem;
            display: block;
          }
        }
      </style>

    </div>
  </div>
</section>


<section class="is-small section">
  <div class="section-container">
      <h2 style="padding-top: 10px;" class="title">Repeatibility</h2>
  

    <div class="hero-body">
      <img style="width: 100%; display: block; margin: 0 auto; padding-bottom: 30px;" src="static/images/repeatbility_new.png" alt="Description">
      <!-- <h2 class="subtitle has-text-centered">
        We evaluated the repeatability of three tactile sensors—ViTacTip, MagicTac, and Gelmini—measuring standard deviation (STD) of force components (F<sub>x</sub>, F<sub>y</sub>, F<sub>z</sub>) and positional components (P<sub>x</sub>, P<sub>y</sub>, P<sub>z</sub>) across multiple trials at various indentation depths. Figure Xa compares sensor structures and dimensions. Figure Xb shows STDs of all six components, while Figure Xc plots repeatability (STD) versus depth, with positional STDs (P<sub>x</sub>, P<sub>y</sub>, P<sub>z</sub>, left y-axis in mm) and force STDs (F<sub>x</sub>, F<sub>y</sub>, F<sub>z</sub>, right y-axis in N) for each sensor: ViTacTip (left), MagicTac (center), and Gelmini (right).
      </h2> -->
      <p><strong>Repeatability Analysis:</strong> We evaluated how consistently each sensor responded to repeated stimuli by conducting 100 compression cycles (in 0.1mm steps to maximum depth) across their surfaces. Using our ResNet-based model, we analyzed standard deviation (STD) of both force (F<sub>xy</sub>, F<sub>z</sub>) and position (P<sub>xy</sub>, P<sub>z</sub>) predictions.</p>

    
      <p><strong>Force Results:</strong> ViTacTip demonstrated superior repeatability with uniformly low STD values across all depths. Gelmini showed moderate performance with slightly elevated STD near its center, while MagicTac exhibited higher force variability.</p>
    
      <p><strong>Position Results:</strong> ViTacTip maintained excellent positional repeatability except during initial shallow indentations. MagicTac showed moderate P<sub>xy</sub> variability, while Gemini displayed the highest inconsistency - particularly at edges due to geometric constraints. The varying step counts reflect each sensor's durability limits under compression.</p>
    </div>


    </div>
  </div>
</section>













<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="section-container">
            <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
